{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c0ae45-ddcd-4d69-a728-3ff939cb4cf7",
   "metadata": {},
   "source": [
    "# Train with bytestrings data when input size is very big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08214f10-1fc0-458b-afa1-c2b1970fb137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys < MIDWAYU-SPECIFIC IMPORTS\n",
    "#sys.path.insert(0, \"/project2/ishanu/DMYTRO/QNET/quasinet\")\n",
    "from quasinet.qnet import *\n",
    "from quasinet.qsampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8ef0baf-5908-4d8c-b4ca-d84b75a6f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "def count_lines(filepath):\n",
    "    result = subprocess.run(['wc', '-l', filepath], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    if result.returncode == 0:\n",
    "        return int(result.stdout.split()[0])\n",
    "    else:\n",
    "        raise Exception(f\"Error counting lines: {result.stderr}\")\n",
    "\n",
    "def read_csv_into_bytearray(filepath, nrows = 0):\n",
    "    \"\"\"\n",
    "        When you know for sure the input data is just \n",
    "        strings of length 1 of \"\"s, it is much faster\n",
    "        to load the csv lines straight into bytestring arrays\n",
    "        Assumes existing csv-style header and patient_id as the first column\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store the rows\n",
    "    rows = []\n",
    "    \n",
    "    # Open the file and read line by line\n",
    "    with open(filepath, 'r') as file:\n",
    "        # Skip the header row\n",
    "        next(file)\n",
    "        \n",
    "        for i, line in tqdm(\n",
    "                enumerate(file), \n",
    "                position = 0, \n",
    "                leave = True,\n",
    "                total = count_lines(filepath)):\n",
    "            if nrows and i >= nrows:\n",
    "                break\n",
    "            # Split the line by comma and ignore the first value\n",
    "            values = line.strip().split(',')[1:]\n",
    "            # Convert to numpy array\n",
    "            values_array = np.array(values, dtype = \"S1\")\n",
    "            rows.append(values_array)\n",
    "            \n",
    "    return np.vstack(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8eeae02-8cca-4222-9c57-ecdc9a1c958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"QNET_TRAINING_SET.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f83f0a88-8b6d-44f1-8c2d-669bdf2c6974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I10_Y75-1-1', 'I10_Y76-1-1', 'I10_Y77-1-1', 'I10_Y78-1-1', 'I10_Y79-1-1']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Load the tree names directly from the input\n",
    "\"\"\"\n",
    "with open(INPUT_PATH, \"r\") as f:\n",
    "    ALL_COLS = f.readline().split(',')\n",
    "    if ALL_COLS[0] == 'patient_id':\n",
    "        ALL_COLS = ALL_COLS[1:]\n",
    "    print(ALL_COLS[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "060032a2-10a1-4ce8-9ef2-7f44f5dd7d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 762/763 [00:00<00:00, 14553.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 61.8 ms, sys: 29.6 ms, total: 91.4 ms\n",
      "Wall time: 117 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = read_csv_into_bytearray(\n",
    "    INPUT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4a1c711-22b6-4796-81d1-ae7d9c8e5a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 143 ms, sys: 4.8 ms, total: 148 ms\n",
      "Wall time: 145 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "    Also load as usual, just to see the difference\n",
    "\"\"\"\n",
    "DF = pd.read_csv(INPUT_PATH, na_filter = False)\n",
    "Xold = DF.iloc[:,1:].values.astype(\"<U1\") #1: removes patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8cb38d8c-bcac-4933-9fa4-08f1d3371b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(762, 528)\n",
      "(762, 528)\n",
      "X (bytestring) SIZE: 0.402 MB\n",
      "X (old style) SIZE: 1.609 MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    COMPARE SIZES\n",
    "\"\"\"\n",
    "import sys\n",
    "print(X.shape)\n",
    "print(Xold.shape)\n",
    "print(f\"X (bytestring) SIZE: {sys.getsizeof(X) / (1000 * 1000):.3f} MB\")\n",
    "print(f\"X (old style) SIZE: {sys.getsizeof(Xold) / (1000 * 1000):.3f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d245e5fb-18e2-4e8f-9699-c4a5086e7f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = 28\n",
    "BATCH_SIZE = 28\n",
    "TREE_COLUMNS = ALL_COLS\n",
    "TREE_BATCHES = []\n",
    "\n",
    "for i in range(0, len(TREE_COLUMNS), BATCH_SIZE):\n",
    "    TREE_BATCHES.append(TREE_COLUMNS[i:i+BATCH_SIZE])\n",
    "    \n",
    "print(len(TREE_BATCHES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3893bc28-300e-4bd1-a5c1-90fe58216a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I10_Y75-1-1', 'I10_Y76-1-1']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TREE_BATCHES[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ae647ff-d9a2-4f27-9f65-21092565ff30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train QNet trees: 100%|██████████| 19/19 [01:42<00:00,  5.39s/batches]\n"
     ]
    }
   ],
   "source": [
    "QNET_PARTS = []\n",
    "\n",
    "for i, BATCH in tqdm(enumerate(TREE_BATCHES), \n",
    "                     \"Train QNet trees\",\n",
    "                    position = 0, \n",
    "                    total = len(TREE_BATCHES),\n",
    "                     unit = 'batches',\n",
    "                    leave = True):\n",
    "    \n",
    "    INDICES = [ALL_COLS.index(column) for column in BATCH]\n",
    "\n",
    "    QNET_PART = Qnet(\n",
    "        feature_names = ALL_COLS,\n",
    "        alpha = 0.1,\n",
    "        n_jobs = N_JOBS,\n",
    "        max_depth = -1,\n",
    "        max_feats = -1,\n",
    "        min_samples_split = 2,\n",
    "        random_state = None,\n",
    "        early_stopping = False,\n",
    "        verbose = 0\n",
    "    ) # !!!!!!!!!!!!!!!\n",
    "\n",
    "    QNET_PART.fit(X, index_array = INDICES)\n",
    "    QNET_PARTS.append(QNET_PART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b1f5258-1158-4cc5-ad9c-fd78b79fc549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cobmine QNet trees into one QNet: 100%|██████████| 19/19 [00:00<00:00, 74.04parts/s]\n"
     ]
    }
   ],
   "source": [
    "FULL_QNET = []\n",
    "\n",
    "for QNET_PART in tqdm(\n",
    "        QNET_PARTS, \n",
    "        \"Cobmine QNet trees into one QNet\",\n",
    "         position = 0,\n",
    "         unit = 'parts',\n",
    "         leave = True):\n",
    "    if not FULL_QNET:\n",
    "        FULL_QNET = QNET_PART\n",
    "    else:\n",
    "        FULL_QNET.mix(QNET_PART, ALL_COLS)\n",
    "        \n",
    "FULL_QNET.training_data = X\n",
    "\n",
    "save_qnet(\n",
    "    FULL_QNET, \n",
    "    f\"FULL_QNET.joblib\", \n",
    "    low_mem = True, gz = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f636d2b0-b889-4397-875a-a0e02ea1ae07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ariadne",
   "language": "python",
   "name": "ariadne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
