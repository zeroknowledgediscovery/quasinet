{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:58:48.946727Z",
     "start_time": "2020-06-25T14:58:48.941093Z"
    }
   },
   "outputs": [],
   "source": [
    "NUMCPUS = 5\n",
    "\n",
    "# MAX_COLS = 20\n",
    "MAX_COLS = None\n",
    "\n",
    "# MAX_ROWS = 10\n",
    "MAX_ROWS = None\n",
    "\n",
    "TRAIN_QNETS = False\n",
    "\n",
    "COMPUTE_QDISTS = False\n",
    "\n",
    "COMPUTE_COMMON_STRAIN = True\n",
    "\n",
    "TYPE = 'h1n1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:31:48.049306Z",
     "start_time": "2020-06-25T14:31:48.043807Z"
    }
   },
   "outputs": [],
   "source": [
    "# DATA_DIR = '/home/jinli11/quasinet/data/influenza/trees/h1n1humanHA/'\n",
    "DATA_DIR = '/project2/ishanu/hiv-dip/influenza/trees/h1n1humanHA/'\n",
    "\n",
    "OUTPUT_DIR = 'output/'\n",
    "\n",
    "INFLUENZA_OUT_DIR = OUTPUT_DIR + 'influenza/'\n",
    "\n",
    "INFLUENZA_QNET_DIR = INFLUENZA_OUT_DIR + 'qnets/'\n",
    "\n",
    "INFLUENZA_QDIST_DIR = INFLUENZA_OUT_DIR + 'qdistances/'\n",
    "\n",
    "HUMAN_HA_YEARLY_DIST_MATRIX_LDISTANCE_DIR = '/project2/ishanu/hiv-dip/influenza/output/yearly_distance_matrices_ldistance/h1n1humanHA/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T15:03:59.451674Z",
     "start_time": "2020-06-25T15:03:59.167889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'compute_common_strain' from '/project2/ishanu/hiv-dip/quasinet/ntb/compute_common_strain.py'>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "\n",
    "# sys.path.insert(1, '/home/jinli11/quasinet/quasinet/citrees/')\n",
    "sys.path.insert(1, '/project2/ishanu/hiv-dip/quasinet/quasinet/citrees/')\n",
    "\n",
    "# import citrees\n",
    "import qnet\n",
    "import tree\n",
    "\n",
    "import compute_common_strain\n",
    "from compute_common_strain import *\n",
    "reload(compute_common_strain)\n",
    "# reload(citrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `jupyter nbconvert --to script influenza.ipynb`\n",
    "* TODO: I need to clean the sequences to reduce redudant sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:54:30.969101Z",
     "start_time": "2020-06-25T14:54:30.954768Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_csv_files(dir_, index_col=None):\n",
    "    f_to_data = {}\n",
    "    for file_ in glob.glob(dir_ + '*.csv'):\n",
    "        f = os.path.basename(file_)\n",
    "        f = re.findall(r'\\d+_\\d+', f)[0]\n",
    "        \n",
    "        f_to_data[f] = pd.read_csv(file_, index_col=index_col)\n",
    "        \n",
    "    return f_to_data\n",
    "\n",
    "    \n",
    "def make_dir(dir_):\n",
    "    \"\"\"Make a directory if it doesn't exist.\n",
    "\n",
    "    Args:\n",
    "        dir (str): directory to make\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.isdir(dir_):\n",
    "        os.makedirs(dir_)\n",
    "        \n",
    "def load_pickled(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_pickled(item, file_name):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(item, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def remove_index_and_cols(f_to_df):\n",
    "    \n",
    "    new_f_to_df = {}\n",
    "    for f, df in f_to_df.items():\n",
    "        df = df.copy(deep=True)\n",
    "        df.index = np.arange(0, df.shape[0])\n",
    "        df.columns = np.arange(0, df.shape[1])\n",
    "        \n",
    "        new_f_to_df[f] = df\n",
    "        \n",
    "    return new_f_to_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Making Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:13:40.596633Z",
     "start_time": "2020-06-25T14:13:40.588970Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "make_dir(INFLUENZA_OUT_DIR)\n",
    "make_dir(INFLUENZA_QNET_DIR)\n",
    "make_dir(INFLUENZA_QDIST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:58:26.829377Z",
     "start_time": "2020-06-25T14:58:24.195965Z"
    }
   },
   "outputs": [],
   "source": [
    "human_ha_seqs = load_csv_files(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:29:33.941693Z",
     "start_time": "2020-06-25T14:29:33.935078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h1n1human2018_2019.csv'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(f_to_seqs.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:13:43.568378Z",
     "start_time": "2020-06-25T14:13:43.566055Z"
    }
   },
   "outputs": [],
   "source": [
    "# list(f_to_seqs.values())[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Qnet Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:13:43.578248Z",
     "start_time": "2020-06-25T14:13:43.569855Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train_qnet(f, seqs, output_dir, max_cols, numCPUs):\n",
    "    seqs = seqs.values.astype(str)[:, :max_cols]\n",
    "    myqnet = qnet.Qnet(n_jobs=numCPUs)\n",
    "    myqnet.fit(seqs)\n",
    "\n",
    "    basename = f.replace('.csv', '.joblib')\n",
    "    if output_dir is not None:\n",
    "        outfile = os.path.join(output_dir, basename)\n",
    "        qnet.save_qnet(myqnet, outfile)\n",
    "        \n",
    "    return basename, myqnet\n",
    "            \n",
    "def train_qnets(f_to_seqs, numCPUs, output_dir, max_cols=None):\n",
    "        \n",
    "    keys = list(f_to_seqs.keys())#[:2]\n",
    "    \n",
    "    base_name_trees = Parallel(n_jobs=numCPUs, backend='loky')(\n",
    "        delayed(train_qnet)(\n",
    "            key, f_to_seqs[key], output_dir, max_cols, numCPUs)\n",
    "        for key in keys\n",
    "        )\n",
    "    \n",
    "    f_to_qnet = {basename: tree for basename, tree in base_name_trees}\n",
    "    return f_to_qnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Qnet Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:13:43.583998Z",
     "start_time": "2020-06-25T14:13:43.580021Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# result = train_qnet(\n",
    "#     'h1n1human2009_2010.csv',\n",
    "#     f_to_seqs['h1n1human2009_2010.csv'], \n",
    "#     output_dir=None, \n",
    "#     max_cols=MAX_COLS, \n",
    "#     numCPUs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:13:43.590160Z",
     "start_time": "2020-06-25T14:13:43.586366Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if TRAIN_QNETS:\n",
    "    f_to_qnets = train_qnets(\n",
    "        f_to_seqs, \n",
    "        numCPUs=NUMCPUS, \n",
    "        output_dir=INFLUENZA_QNET_DIR, \n",
    "        max_cols=MAX_COLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDistance Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:13:43.603501Z",
     "start_time": "2020-06-25T14:13:43.592073Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_qnets(dir_):\n",
    "    f_to_qnets = {}\n",
    "    for f in glob.glob(dir_ + \"*.joblib\"):\n",
    "        f_to_qnets[os.path.basename(f)] = qnet.load_qnet(f)\n",
    "        \n",
    "    return f_to_qnets\n",
    "\n",
    "def compute_qdist(f, seqs, myqnet, max_seqs, max_cols):\n",
    "    seqs = seqs.drop_duplicates()\n",
    "    indices = seqs.index[:max_seqs]\n",
    "    seqs = seqs.values\n",
    "\n",
    "    dm = qnet.qdistance_matrix(\n",
    "        seqs[:max_seqs, :max_cols], \n",
    "        seqs[:max_seqs, :max_cols],\n",
    "        myqnet, \n",
    "        myqnet)\n",
    "\n",
    "    dm = pd.DataFrame(dm, index=indices, columns=indices)\n",
    "\n",
    "    return f, dm\n",
    "    \n",
    "def compute_qdists(f_to_qnets, f_to_seqs, max_seqs, max_cols, numCPUs, outdir):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    keys = list(f_to_seqs.keys())#[:2]\n",
    "    qnet_names = [key.split('.')[0] + '.joblib' for key in keys]\n",
    "    \n",
    "    f_dms = Parallel(n_jobs=numCPUs, backend='loky')(\n",
    "        delayed(compute_qdist)(\n",
    "            key, f_to_seqs[key], f_to_qnets[qnet_names[i]], max_seqs, max_cols)\n",
    "        for i, key in enumerate(keys)\n",
    "        )\n",
    "    \n",
    "    f_to_dms = {}\n",
    "    for f, dm in f_dms:\n",
    "        f_to_dms[f] = dm\n",
    "        dm.to_csv(os.path.join(outdir, f))\n",
    "#     f_to_dms = {f: dm for f, dm in f_dms}\n",
    "    \n",
    "    return f_to_dms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:13:43.610131Z",
     "start_time": "2020-06-25T14:13:43.605095Z"
    }
   },
   "outputs": [],
   "source": [
    "# f_to_qnets = load_qnets(INFLUENZA_QNET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:13:43.615299Z",
     "start_time": "2020-06-25T14:13:43.611794Z"
    }
   },
   "outputs": [],
   "source": [
    "# sys.getsizeof(f_to_qnets['h1n1human2000_2001.joblib'].estimators_) #.estimators_[1].root\n",
    "# tree.get_nodes(f_to_qnets['h1n1human2000_2001.joblib'].estimators_[2].root)\n",
    "# save_pickled(f_to_qnets['h1n1human2000_2001.joblib'], 'TMP.pkl')\n",
    "# save_pickled(f_to_qnets['h1n1human2000_2001.joblib'].estimators_, 'TMP2.pkl')\n",
    "# save_pickled(f_to_qnets['h1n1human2000_2001.joblib'].estimators_[0], 'TMP3.pkl')\n",
    "# f_to_qnets['h1n1human2000_2001.joblib'].estimators_[0].feature_importances_.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:13:43.620728Z",
     "start_time": "2020-06-25T14:13:43.617061Z"
    }
   },
   "outputs": [],
   "source": [
    "if COMPUTE_QDISTS:\n",
    "    qdist = compute_qdists(\n",
    "        f_to_qnets, human_ha_seqs, max_seqs=MAX_ROWS, \n",
    "        max_cols=MAX_COLS, numCPUs=NUMCPUS ** 2, outdir=INFLUENZA_QDIST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:33:32.385063Z",
     "start_time": "2020-06-25T14:33:28.946342Z"
    }
   },
   "outputs": [],
   "source": [
    "human_ha_qdistance_dm = load_csv_files(INFLUENZA_QDIST_DIR, index_col=0)\n",
    "human_ha_ldistance_dm = load_csv_files(HUMAN_HA_YEARLY_DIST_MATRIX_LDISTANCE_DIR, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:54:54.811756Z",
     "start_time": "2020-06-25T14:54:54.808271Z"
    }
   },
   "outputs": [],
   "source": [
    "# human_ha_qdistance_dm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:54:53.358495Z",
     "start_time": "2020-06-25T14:54:53.354941Z"
    }
   },
   "outputs": [],
   "source": [
    "# list(human_ha_qdistance_dm.values())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Common Strain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Compute Dominant Strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T15:09:37.878371Z",
     "start_time": "2020-06-25T15:09:37.854814Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compute_dominant_strain(\n",
    "    name_to_dm, n_clusters, file_to_seqs=None, \n",
    "    remove_outliers=False,\n",
    "    clustering_method='agg',\n",
    "    min_type='average'):\n",
    "    \"\"\"Seperate the sequences into clusters, find the largest cluster, and find the \n",
    "    centroid of that largest cluster.\n",
    "    \n",
    "    Args:\n",
    "        name_to_dm (dict): mapping file name to distance matrix\n",
    "        use_accession (bool): whether we are using the accession or not\n",
    "        min_type (str): which type to use to compute the minimum\n",
    "        remove_outliers (bool): whether to remove outliers. N\n",
    "    \"\"\"\n",
    "    \n",
    "    dominant_strains = []\n",
    "    names = []\n",
    "    seqs = []\n",
    "    accession_names = []\n",
    "    for name_, dm in name_to_dm.items():\n",
    "        name = name_\n",
    "        dm.fillna(0, inplace=True)\n",
    "        names.append(name)\n",
    "        columns = dm.columns.astype(str)\n",
    "        index = dm.index.astype(str)\n",
    "        \n",
    "        if dm.shape[0] == dm.shape[1]:\n",
    "            dm = dm.values + dm.T.values\n",
    "            \n",
    "        dm = pd.DataFrame(dm, columns=columns, index=index)\n",
    "        \n",
    "        if remove_outliers:\n",
    "            dm = remove_outliers_func(dm)\n",
    "            \n",
    "        if min_type in ['average', 'median']:\n",
    "            if n_clusters == 1:\n",
    "                sub_dm = dm\n",
    "            else:\n",
    "                clusters = find_clusters(\n",
    "                    dm, n_clusters=n_clusters, \n",
    "                    cluster_type=clustering_method)\n",
    "                \n",
    "                sub_dm = find_largest_cluster_dm(dm, clusters)\n",
    "\n",
    "            if dm.shape == (1, 1):\n",
    "                dominant_strain = dm.index[0]\n",
    "            else:\n",
    "                if min_type == 'average':\n",
    "                    aggregated = sub_dm.sum(axis=1)\n",
    "                elif min_type == 'median':\n",
    "                    aggregated = sub_dm.median(axis=1)\n",
    "                else:\n",
    "                    raise ValueError\n",
    "                    \n",
    "                dominant_strain = aggregated.idxmin()\n",
    "                #dominant_strain = np.argsort(aggregated)[len(aggregated)//2]\n",
    "                \n",
    "        elif min_type == 'normal':\n",
    "            \n",
    "            embedding = MDS(\n",
    "                n_components=1, \n",
    "                dissimilarity=\"precomputed\", \n",
    "                random_state=42)\n",
    "            \n",
    "            embed = embedding.fit_transform(dm)[:,0]\n",
    "            \n",
    "            dominant_strain = dm.index[np.argsort(embed)[len(embed)//2]]\n",
    "            \n",
    "        else:\n",
    "            raise ValueError('Not a correct type: {}'.format(min_type))\n",
    "\n",
    "        dominant_strains.append(dominant_strain)\n",
    "        \n",
    "        \n",
    "        assert file_to_seqs is not None\n",
    "\n",
    "        try:\n",
    "            dominant_strain = int(dominant_strain)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        seq = ''.join(file_to_seqs[name].iloc[dominant_strain])\n",
    "        accession_name = '____'\n",
    "           \n",
    "        accession_names.append(accession_name)\n",
    "        seqs.append(seq)\n",
    "        \n",
    "        \n",
    "    data = pd.DataFrame({\n",
    "        'name': names,\n",
    "        'dominant_strains': dominant_strains,\n",
    "        'sequence': seqs,\n",
    "        'accession_name': accession_names\n",
    "    })\n",
    "    \n",
    "    data.sort_values(by='name', inplace=True)\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T15:20:27.986562Z",
     "start_time": "2020-06-25T15:20:27.968807Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_ldistances(seqs1, seqs2, max_size=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    NOTE: if seq1 or seq2 is blank, we return -1.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(seqs1) == len(seqs2)\n",
    "    \n",
    "    ldist = []\n",
    "    for i, seq1 in enumerate(seqs1):\n",
    "        seq2 = seqs2[i]\n",
    "        \n",
    "        if seq1 == '-1' or seq2 == '-1':\n",
    "            dist = -1\n",
    "        else:\n",
    "            dist = Levenshtein.distance(seq1[:max_size], seq2[:max_size])\n",
    "            \n",
    "        ldist.append(dist)\n",
    "        \n",
    "    return ldist\n",
    "\n",
    "\n",
    "def merge_prediction_data(\n",
    "    WHO_rec, \n",
    "    qnet_rec, dominant_strains, subtype, \n",
    "    f_to_seqs,\n",
    "    outfile=None,\n",
    "    max_size=None):\n",
    "    \n",
    "    WHO_rec = WHO_rec.reset_index(drop=True)\n",
    "    qnet_rec = qnet_rec.reset_index(drop=True)\n",
    "    dominant_strains = dominant_strains.reset_index(drop=True)\n",
    "    \n",
    "    data = pd.DataFrame({'year': WHO_rec['year'].values})\n",
    "    data['WHO_recommendation_name'] = WHO_rec['name']\n",
    "    data['WHO_recommendation_sequence'] = WHO_rec[subtype]\n",
    "    \n",
    "    data['dominant_strain_accession'] = list(dominant_strains['dominant_strains'].values[1:]) + ['-1']\n",
    "    data['dominant_strain_sequence'] = list(dominant_strains['sequence'].values[1:]) + ['-1']\n",
    "    \n",
    "    dom_strain_acc_name = list(dominant_strains['accession_name'].values[1:])\n",
    "#     dom_strain_acc_name = list(map(parse_influenza_name, dom_strain_acc_name))\n",
    "    dom_strain_acc_name = dom_strain_acc_name + ['-1']\n",
    "    data['dominant_strain_accession_name'] = dom_strain_acc_name\n",
    "    \n",
    "    data['qdistance_recommendation_accession'] = qnet_rec['dominant_strains']\n",
    "    data['qdistance_recommendation_sequence'] = qnet_rec['sequence']\n",
    "    \n",
    "#     qdist_acc_name = list(map(parse_influenza_name, qnet_rec['accession_name']))\n",
    "    qdist_acc_name = qnet_rec['accession_name']\n",
    "    data['qdistance_recommendation_accession_name'] = qdist_acc_name\n",
    "    \n",
    "#     import pdb; pdb.set_trace()\n",
    "    ldistance_WHO = compute_ldistances(\n",
    "        data['WHO_recommendation_sequence'][:-1],\n",
    "        data['dominant_strain_sequence'][:-1],\n",
    "        max_size=max_size)\n",
    "    \n",
    "    ldistance_qnet_rec = compute_ldistances(\n",
    "        data['qdistance_recommendation_sequence'][:-1],\n",
    "        data['dominant_strain_sequence'][:-1],\n",
    "        max_size=max_size)\n",
    "    \n",
    "    data['ldistance_WHO'] = ldistance_WHO + [-1]\n",
    "    data['ldistance_Qnet_recommendation'] = ldistance_qnet_rec + [-1]\n",
    "    \n",
    "    num_rows = data.shape[0]\n",
    "    num_samples = []\n",
    "    for i in range(num_rows):\n",
    "        year_range = data['year'].iloc[i]\n",
    "        year = year_range.split('_')[0]\n",
    "        if year_range in f_to_seqs:\n",
    "            num_samples.append(f_to_seqs[year_range].shape[0])\n",
    "        else:\n",
    "            num_samples.append(-1)\n",
    "            \n",
    "    data['qnet_sample_size'] = num_samples\n",
    "            \n",
    "    if outfile is not None:\n",
    "        data.to_csv(outfile, index=None)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T14:56:58.787121Z",
     "start_time": "2020-06-25T14:56:58.783067Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 2\n",
    "NUM_CLUSTERS_QDIST = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T15:05:15.187128Z",
     "start_time": "2020-06-25T15:05:15.183605Z"
    }
   },
   "outputs": [],
   "source": [
    "# list(human_ha_ldistance_dm.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T15:10:27.418304Z",
     "start_time": "2020-06-25T15:10:26.715713Z"
    }
   },
   "outputs": [],
   "source": [
    "if COMPUTE_COMMON_STRAIN:\n",
    "\n",
    "#     ha_dominant_strains_ldist = compute_dominant_strain(\n",
    "#         remove_index_and_cols(human_ha_ldistance_dm),\n",
    "#         NUM_CLUSTERS,\n",
    "#         None,\n",
    "#         HUMAN_HA_YEARLY_DIST_MATRIX_LDISTANCE_DIR,\n",
    "#         use_accession=False, \n",
    "#         file_to_seqs=human_ha_seqs, \n",
    "#         file_to_seqs_base_dir='{}human'.format(TYPE, TYPE))\n",
    "    \n",
    "    ha_dominant_strains_ldist = compute_dominant_strain(\n",
    "        name_to_dm=remove_index_and_cols(human_ha_ldistance_dm), \n",
    "        n_clusters=NUM_CLUSTERS, \n",
    "        file_to_seqs=human_ha_seqs, \n",
    "        remove_outliers=False)\n",
    "    \n",
    "    ha_dominant_strains_qdist = compute_dominant_strain(\n",
    "        name_to_dm=remove_index_and_cols(human_ha_qdistance_dm), \n",
    "        n_clusters=1, \n",
    "        file_to_seqs=human_ha_seqs, \n",
    "        remove_outliers=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T15:13:41.922014Z",
     "start_time": "2020-06-25T15:13:41.909657Z"
    }
   },
   "outputs": [],
   "source": [
    "WHO_recommendations = pd.read_csv(\n",
    "    '/project2/ishanu/hiv-dip/influenza/data/WHO_recommendations_Northern_Hemisphere.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T15:20:30.195838Z",
     "start_time": "2020-06-25T15:20:30.162626Z"
    }
   },
   "outputs": [],
   "source": [
    "# ha_dominant_strains_qdist\n",
    "human_ha_max_len = 550\n",
    "humanHA_recommendations = merge_prediction_data(\n",
    "    WHO_recommendations, \n",
    "    ha_dominant_strains_qdist, \n",
    "    ha_dominant_strains_ldist, \n",
    "    'HA_seq',\n",
    "    human_ha_seqs,\n",
    "    outfile=None,\n",
    "    max_size=human_ha_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T15:20:33.378953Z",
     "start_time": "2020-06-25T15:20:33.355473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>WHO_recommendation_name</th>\n",
       "      <th>WHO_recommendation_sequence</th>\n",
       "      <th>dominant_strain_accession</th>\n",
       "      <th>dominant_strain_sequence</th>\n",
       "      <th>dominant_strain_accession_name</th>\n",
       "      <th>qdistance_recommendation_accession</th>\n",
       "      <th>qdistance_recommendation_sequence</th>\n",
       "      <th>qdistance_recommendation_accession_name</th>\n",
       "      <th>ldistance_WHO</th>\n",
       "      <th>ldistance_Qnet_recommendation</th>\n",
       "      <th>qnet_sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001_2002</td>\n",
       "      <td>A/New Caledonia/20/99</td>\n",
       "      <td>MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>0</td>\n",
       "      <td>MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>5</td>\n",
       "      <td>MKAKLLVLLCAFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002_2003</td>\n",
       "      <td>A/New Caledonia/20/99</td>\n",
       "      <td>MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>5</td>\n",
       "      <td>MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>36</td>\n",
       "      <td>MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003_2004</td>\n",
       "      <td>A/New Caledonia/20/99</td>\n",
       "      <td>MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>0</td>\n",
       "      <td>MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>3</td>\n",
       "      <td>MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004_2005</td>\n",
       "      <td>A/New Caledonia/20/99</td>\n",
       "      <td>MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>0</td>\n",
       "      <td>MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>5</td>\n",
       "      <td>MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005_2006</td>\n",
       "      <td>A/New Caledonia/20/99</td>\n",
       "      <td>MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>1</td>\n",
       "      <td>MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>0</td>\n",
       "      <td>MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006_2007</td>\n",
       "      <td>A/New Caledonia/20/99</td>\n",
       "      <td>MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>25</td>\n",
       "      <td>MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>0</td>\n",
       "      <td>MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007_2008</td>\n",
       "      <td>A/Solomon Islands/3/2006</td>\n",
       "      <td>MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>81</td>\n",
       "      <td>MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>11</td>\n",
       "      <td>MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008_2009</td>\n",
       "      <td>A/Brisbane/59/2007</td>\n",
       "      <td>MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>227</td>\n",
       "      <td>MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>263</td>\n",
       "      <td>MKVKLLILLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009_2010</td>\n",
       "      <td>A/Brisbane/59/2007</td>\n",
       "      <td>MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>4</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>49</td>\n",
       "      <td>MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>119</td>\n",
       "      <td>118</td>\n",
       "      <td>7162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010_2011</td>\n",
       "      <td>A/California/7/2009</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>29</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>4</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2011_2012</td>\n",
       "      <td>A/California/7/2009</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>326</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>29</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012_2013</td>\n",
       "      <td>A/California/7/2009</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>15</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>77</td>\n",
       "      <td>MKAILVVLLYTFATTNADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013_2014</td>\n",
       "      <td>A/California/7/2009</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>350</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>123</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014_2015</td>\n",
       "      <td>A/California/7/2009</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>3</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>0</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015_2016</td>\n",
       "      <td>A/California/7/2009</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>1</td>\n",
       "      <td>MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>1</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016_2017</td>\n",
       "      <td>A/California/7/2009</td>\n",
       "      <td>MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>8</td>\n",
       "      <td>MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>1</td>\n",
       "      <td>MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017_2018</td>\n",
       "      <td>A/Michigan/45/2015</td>\n",
       "      <td>MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>1</td>\n",
       "      <td>MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>3</td>\n",
       "      <td>MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018_2019</td>\n",
       "      <td>A/Michigan/45/2015</td>\n",
       "      <td>MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>0</td>\n",
       "      <td>MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>16</td>\n",
       "      <td>MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019_2020</td>\n",
       "      <td>A/Brisbane/02/2018</td>\n",
       "      <td>MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>29</td>\n",
       "      <td>MKVILVVLLCTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>0</td>\n",
       "      <td>MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020_2021</td>\n",
       "      <td>A/Hawaii/70/2019</td>\n",
       "      <td>MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>245</td>\n",
       "      <td>MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "      <td>____</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         year   WHO_recommendation_name  \\\n",
       "0   2001_2002     A/New Caledonia/20/99   \n",
       "1   2002_2003     A/New Caledonia/20/99   \n",
       "2   2003_2004     A/New Caledonia/20/99   \n",
       "3   2004_2005     A/New Caledonia/20/99   \n",
       "4   2005_2006     A/New Caledonia/20/99   \n",
       "5   2006_2007     A/New Caledonia/20/99   \n",
       "6   2007_2008  A/Solomon Islands/3/2006   \n",
       "7   2008_2009        A/Brisbane/59/2007   \n",
       "8   2009_2010        A/Brisbane/59/2007   \n",
       "9   2010_2011       A/California/7/2009   \n",
       "10  2011_2012       A/California/7/2009   \n",
       "11  2012_2013       A/California/7/2009   \n",
       "12  2013_2014       A/California/7/2009   \n",
       "13  2014_2015       A/California/7/2009   \n",
       "14  2015_2016       A/California/7/2009   \n",
       "15  2016_2017       A/California/7/2009   \n",
       "16  2017_2018        A/Michigan/45/2015   \n",
       "17  2018_2019        A/Michigan/45/2015   \n",
       "18  2019_2020        A/Brisbane/02/2018   \n",
       "19  2020_2021          A/Hawaii/70/2019   \n",
       "\n",
       "                          WHO_recommendation_sequence  \\\n",
       "0   MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "1   MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "2   MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "3   MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "4   MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "5   MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "6   MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "7   MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "8   MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "9   MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "10  MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "11  MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "12  MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "13  MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "14  MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "15  MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "16  MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "17  MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "18  MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "19  MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "\n",
       "   dominant_strain_accession  \\\n",
       "0                          0   \n",
       "1                          5   \n",
       "2                          0   \n",
       "3                          0   \n",
       "4                          1   \n",
       "5                         25   \n",
       "6                         81   \n",
       "7                        227   \n",
       "8                          4   \n",
       "9                         29   \n",
       "10                       326   \n",
       "11                        15   \n",
       "12                       350   \n",
       "13                         3   \n",
       "14                         1   \n",
       "15                         8   \n",
       "16                         1   \n",
       "17                         0   \n",
       "18                        29   \n",
       "19                        -1   \n",
       "\n",
       "                             dominant_strain_sequence  \\\n",
       "0   MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "1   MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "2   MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "3   MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "4   MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "5   MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "6   MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "7   MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "8   MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "9   MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "10  MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "11  MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "12  MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "13  MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "14  MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "15  MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "16  MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "17  MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "18  MKVILVVLLCTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "19                                                 -1   \n",
       "\n",
       "   dominant_strain_accession_name qdistance_recommendation_accession  \\\n",
       "0                            ____                                  5   \n",
       "1                            ____                                 36   \n",
       "2                            ____                                  3   \n",
       "3                            ____                                  5   \n",
       "4                            ____                                  0   \n",
       "5                            ____                                  0   \n",
       "6                            ____                                 11   \n",
       "7                            ____                                263   \n",
       "8                            ____                                 49   \n",
       "9                            ____                                  4   \n",
       "10                           ____                                 29   \n",
       "11                           ____                                 77   \n",
       "12                           ____                                123   \n",
       "13                           ____                                  0   \n",
       "14                           ____                                  1   \n",
       "15                           ____                                  1   \n",
       "16                           ____                                  3   \n",
       "17                           ____                                 16   \n",
       "18                           ____                                  0   \n",
       "19                             -1                                245   \n",
       "\n",
       "                    qdistance_recommendation_sequence  \\\n",
       "0   MKAKLLVLLCAFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "1   MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "2   MKAKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "3   MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "4   MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "5   MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "6   MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "7   MKVKLLILLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "8   MKVKLLVLLCTFTATYADTICIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "9   MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "10  MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "11  MKAILVVLLYTFATTNADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "12  MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "13  MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "14  MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "15  MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "16  MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "17  MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "18  MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "19  MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...   \n",
       "\n",
       "   qdistance_recommendation_accession_name  ldistance_WHO  \\\n",
       "0                                     ____              4   \n",
       "1                                     ____              3   \n",
       "2                                     ____              5   \n",
       "3                                     ____             12   \n",
       "4                                     ____              8   \n",
       "5                                     ____             11   \n",
       "6                                     ____             14   \n",
       "7                                     ____              6   \n",
       "8                                     ____            119   \n",
       "9                                     ____              5   \n",
       "10                                    ____              9   \n",
       "11                                    ____             13   \n",
       "12                                    ____             12   \n",
       "13                                    ____             12   \n",
       "14                                    ____             14   \n",
       "15                                    ____             19   \n",
       "16                                    ____              5   \n",
       "17                                    ____              6   \n",
       "18                                    ____              8   \n",
       "19                                    ____             -1   \n",
       "\n",
       "    ldistance_Qnet_recommendation  qnet_sample_size  \n",
       "0                              31               223  \n",
       "1                               1                16  \n",
       "2                               9                42  \n",
       "3                               6                 3  \n",
       "4                              10                72  \n",
       "5                               8               146  \n",
       "6                              11               636  \n",
       "7                              19               593  \n",
       "8                             118              7162  \n",
       "9                               4              1438  \n",
       "10                              4               974  \n",
       "11                             12               537  \n",
       "12                              2              1036  \n",
       "13                              0               686  \n",
       "14                              3               672  \n",
       "15                              7              2237  \n",
       "16                             11               995  \n",
       "17                              3              1775  \n",
       "18                              4               724  \n",
       "19                             -1                -1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humanHA_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T15:10:38.118117Z",
     "start_time": "2020-06-25T15:10:38.114651Z"
    }
   },
   "outputs": [],
   "source": [
    "# ha_dominant_strains_ldist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quasinet_new",
   "language": "python",
   "name": "quasinet_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
