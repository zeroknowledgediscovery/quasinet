{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Parameters to Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:26:47.555285Z",
     "start_time": "2020-06-21T20:26:47.552338Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "NUMCPUS = 4\n",
    "\n",
    "MAX_COLS = 20\n",
    "\n",
    "MAX_ROWS = 10\n",
    "\n",
    "TRAIN_QNETS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:26:50.375099Z",
     "start_time": "2020-06-21T20:26:50.370617Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/jinli11/quasinet/data/influenza/trees/h1n1humanHA/'\n",
    "\n",
    "OUTPUT_DIR = 'output/'\n",
    "\n",
    "INFLUENZA_OUT_DIR = OUTPUT_DIR + 'influenza/'\n",
    "\n",
    "INFLUENZA_QNET_DIR = INFLUENZA_OUT_DIR + 'qnets/'\n",
    "\n",
    "INFLUENZA_QDIST_DIR = INFLUENZA_OUT_DIR + 'qdistances/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:27:57.807266Z",
     "start_time": "2020-06-21T20:27:57.794303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'qnet' from '/home/jinli11/quasinet/quasinet/citrees/qnet.py'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "\n",
    "sys.path.insert(1, '/home/jinli11/quasinet/quasinet/citrees/')\n",
    "\n",
    "# import citrees\n",
    "import qnet\n",
    "import tree\n",
    "\n",
    "reload(qnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:26:51.299867Z",
     "start_time": "2020-06-21T20:26:51.293241Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_csv_files(dir_):\n",
    "    f_to_data = {}\n",
    "    for f in glob.glob(dir_ + '*.csv'):\n",
    "        f_to_data[os.path.basename(f)] = pd.read_csv(f)\n",
    "        \n",
    "    return f_to_data\n",
    "\n",
    "    \n",
    "def make_dir(dir_):\n",
    "    \"\"\"Make a directory if it doesn't exist.\n",
    "\n",
    "    Args:\n",
    "        dir (str): directory to make\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.isdir(dir_):\n",
    "        os.makedirs(dir_)\n",
    "        \n",
    "def load_pickled(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_pickled(item, file_name):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(item, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Making Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:26:51.615428Z",
     "start_time": "2020-06-21T20:26:51.612743Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "make_dir(INFLUENZA_OUT_DIR)\n",
    "make_dir(INFLUENZA_QNET_DIR)\n",
    "make_dir(INFLUENZA_QDIST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:26:55.043605Z",
     "start_time": "2020-06-21T20:26:51.974997Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f_to_seqs = load_csv_files(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:26:56.702508Z",
     "start_time": "2020-06-21T20:26:56.699119Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# list(f_to_seqs.values())[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qnet Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:29:38.336191Z",
     "start_time": "2020-06-21T20:29:38.322210Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_qnet(f, seqs, output_dir, max_cols, numCPUs):\n",
    "    seqs = seqs.values.astype(str)[:, :max_cols]\n",
    "    myqnet = qnet.Qnet(n_jobs=numCPUs)\n",
    "    myqnet.fit(seqs)\n",
    "\n",
    "    basename = f.replace('.csv', '.joblib')\n",
    "    if output_dir is not None:\n",
    "        outfile = os.path.join(output_dir, basename)\n",
    "        qnet.save_qnet(myqnet, outfile)\n",
    "        \n",
    "    return basename, myqnet\n",
    "            \n",
    "def train_qnets(f_to_seqs, numCPUs, output_dir, max_cols=None):\n",
    "        \n",
    "    keys = list(f_to_seqs.keys())[:2]\n",
    "    \n",
    "    base_name_trees = Parallel(n_jobs=numCPUs, backend='loky')(\n",
    "        delayed(train_qnet)(\n",
    "            key, f_to_seqs[key], output_dir, max_cols, numCPUs)\n",
    "        for key in keys\n",
    "        )\n",
    "    \n",
    "    f_to_qnet = {basename: tree for basename, tree in base_name_trees}\n",
    "    return f_to_qnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qnet Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:29:42.249895Z",
     "start_time": "2020-06-21T20:29:39.584760Z"
    }
   },
   "outputs": [],
   "source": [
    "if TRAIN_QNETS:\n",
    "    f_to_qnets = train_qnets(\n",
    "        f_to_seqs, \n",
    "        numCPUs=NUMCPUS, \n",
    "        output_dir=INFLUENZA_QNET_DIR, \n",
    "        max_cols=MAX_COLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDistance Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:08:27.838221Z",
     "start_time": "2020-06-21T20:08:27.834683Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_qnets(dir_):\n",
    "    f_to_qnets = {}\n",
    "    for f in glob.glob(dir_ + \"*.joblib\"):\n",
    "        f_to_qnets[os.path.basename(f)] = qnet.load_qnet(f)\n",
    "        \n",
    "    return f_to_qnets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:08:27.890040Z",
     "start_time": "2020-06-21T20:08:27.839514Z"
    }
   },
   "outputs": [],
   "source": [
    "# f_to_qnets = load_qnets(INFLUENZA_QNET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:08:27.940249Z",
     "start_time": "2020-06-21T20:08:27.891489Z"
    }
   },
   "outputs": [],
   "source": [
    "# sys.getsizeof(f_to_qnets['h1n1human2000_2001.joblib'].estimators_) #.estimators_[1].root\n",
    "# tree.get_nodes(f_to_qnets['h1n1human2000_2001.joblib'].estimators_[2].root)\n",
    "# save_pickled(f_to_qnets['h1n1human2000_2001.joblib'], 'TMP.pkl')\n",
    "# save_pickled(f_to_qnets['h1n1human2000_2001.joblib'].estimators_, 'TMP2.pkl')\n",
    "# save_pickled(f_to_qnets['h1n1human2000_2001.joblib'].estimators_[0], 'TMP3.pkl')\n",
    "# f_to_qnets['h1n1human2000_2001.joblib'].estimators_[0].feature_importances_.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:42:32.506961Z",
     "start_time": "2020-06-21T20:42:32.492753Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_qdist(f, seqs, myqnet, max_seqs, max_cols):\n",
    "    seqs = seqs.drop_duplicates()\n",
    "    indices = seqs.index[:max_seqs]\n",
    "    seqs = seqs.values\n",
    "\n",
    "    dm = qnet.qdistance_matrix(\n",
    "        seqs[:max_seqs, :max_cols], \n",
    "        seqs[:max_seqs, :max_cols],\n",
    "        myqnet, \n",
    "        myqnet)\n",
    "\n",
    "    dm = pd.DataFrame(dm, index=indices, columns=indices)\n",
    "\n",
    "    return f, dm\n",
    "    \n",
    "def compute_qdists(f_to_qnets, f_to_seqs, max_seqs, max_cols, numCPUs, outdir):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    keys = list(f_to_seqs.keys())[:2]\n",
    "    qnet_names = [key.split('.')[0] + '.joblib' for key in keys]\n",
    "    \n",
    "    f_dms = Parallel(n_jobs=numCPUs, backend='loky')(\n",
    "        delayed(compute_qdist)(\n",
    "            key, f_to_seqs[key], f_to_qnets[qnet_names[i]], max_seqs, max_cols)\n",
    "        for i, key in enumerate(keys)\n",
    "        )\n",
    "    \n",
    "    f_to_dms = {}\n",
    "    for f, dm in f_dms:\n",
    "        f_to_dms[f] = dm\n",
    "        dm.to_csv(os.path.join(outdir, f))\n",
    "#     f_to_dms = {f: dm for f, dm in f_dms}\n",
    "    \n",
    "    return f_to_dms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:42:36.551180Z",
     "start_time": "2020-06-21T20:42:32.845236Z"
    }
   },
   "outputs": [],
   "source": [
    "qdist = compute_qdists(\n",
    "    f_to_qnets, f_to_seqs, max_seqs=MAX_ROWS, \n",
    "    max_cols=MAX_COLS, numCPUs=NUMCPUS, outdir=INFLUENZA_QDIST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T20:42:36.555264Z",
     "start_time": "2020-06-21T20:42:36.553203Z"
    }
   },
   "outputs": [],
   "source": [
    "# qdist['h1n1human2000_2001.csv']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quasinet",
   "language": "python",
   "name": "quasinet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
